<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Aprendizaje Supervisado</title>
    <meta charset="utf-8" />
    <meta name="author" content="Roi Naveiro" />
    <meta name="date" content="2021-06-16" />
    <script src="libs/header-attrs-2.8/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Aprendizaje Supervisado
## Curso JAE ICMAT 2021
### Roi Naveiro
### 2021-06-16

---

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      Xcal: "{\\mathcal{X}}",
      Xbf: "{\\mathbf{X}}",
      Zbf: "{\\mathbf{Z}}",
      Vbf: "{\\mathbf{V}}",
      Hbf: "{\\mathbf{H}}",
      Rbb: "{\\mathbb{R}}"
    },
    extensions: ["AMSmath.js","AMSsymbols.js"]
  }
});
</script>

# El problema

* Tenemos disponibles datos con múltiples observaciones:
   
   * ejemplos (*examples*)
   * muestras (*samples*)

--

* Varias variables por observación, `\(x\)`:
  
  * predictores
  * atributos (*atributes*)
  * características (*features*)
  * covariables (*covariates*)
  * variables independientes
  * variables explicativas

--

* Una de ellas es de especial interés, `\(y\)`: 
  
  * variable respuesta
  * variable dependiente
  * objetivo (*target*)
  * salida (*output*)
  * etiqueta (*label*)
  
---

## Objetivos

  1. Obtener información sobre la **relación de asociación** entre las covariables y la variable dependiente  (**inferencia**)
  
    * ¿Qué variables influyen en la respuesta?
    * ¿Cuánto cambia la respuesta frente a un cambio en una covariable?
    * ...
    
  2. Predecir el valor de la variable respuesta para nuevas observaciones (**inferencia predictiva**)

  3. ¿Causalidad?


???

Información sobre la relación, por ej: qué variables son más relevantes

---

## Tipos de problemas

  1. Regresión, si `\(y \in \mathbb{R}^d\)`
  
  2. Clasificación, si la variable respuesta toma valores en un conjunto discreto no ordenado
  
  3. Otros: 
    
    * `\(y \in \mathbb  Q\)`
    
    * `\(y\)` toma valores en un conjunto discreto ordenado
  
---

## Enfoque probabilístico

  1) **Modelización**: variable respuesta (dadas las covariables) es muestra iid de una distribución de probabilidad determinada, `\(p(y \vert x, w)\)`, parametrizada con `\(w\)`.
  
  2) **Estimación**: Dado un conjunto de entrenamiento `\(S = \{y_i, x_i\}_{i=1}^n\)`
  encontrar los "mejores" valores de `\(w\)`. Dos enfoques:
  * Frecuentista, maximizar verosimulitud
  $$
  w^* = \arg\max_{w}  \prod_i p(y_i \vert x_i, w)
  $$
  * Bayesiana, modelizar incertidumbre sobre los parámetros con un prior, y calcular posterior (dados los datos de entrenamiento)
  $$
  p(w | S) = \frac{p(S \vert w) p(w)}{p(S)}
  $$
  
  
---

## Enfoque probabilístico

  3) **Predicción**: dado un nuevo vector de covariables `\(x\)`, asignar un valor de respuesta `\(y\)`. Idea:
  
  $$
  y^* = \int u(y_D, y) p(y \vert x) dy
  $$
  
  * Ejercicio: ¿Cómo se calcula `\(p(y \vert x)\)` en el paradigma Bayesiano?
  
  
  
---

## Regresión Lineal

Dado el conjunto de entrenamiento `\(S = \{y_i, x_i\}_{i=1}^n\)`


* Agrupamos todos los ejemplos de entrada `\(x_i\)` en una matrix `\(\mathbf{X}\)` de tamaño `\(n \times d\)`

* Agrupamos todas las salidas en un vector columna `\(y\)` de tamaño `\(n \times 1\)`


Modelo `\(y \sim \mathcal{N} (w^T x, \sigma^2)\)`

Estimador de máxima verosimilitud:  `$$\min_w\, ||y - \Xbf w||_2^2$$`
Demuéstralo.


---
## Regresión Lineal

Gradiente: `$$\nabla_w ||y - \Xbf w||_2^2 = 2\mathbf{X}^T(y - \mathbf{X}w) = \mathbf{X}^Ty - \mathbf{X}^T\mathbf{X}w$$`

Minimizamos: `$$\nabla_w ||y - \Xbf w||_2^2 = 0\quad \Rightarrow \quad  w^* = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T y$$`

Recuperamos mínimos cuadrados ordinarios!


---
## Regresión Logística


* La salida `\(y\)` es discreta, `\(y \in \{ 0, 1 \}\)`


* Modelo, `\(y\)` sigue una distribución de Bernoulli con parámetro `\(p\)` tal que
$$
p = \sigma(w^T x) = \frac{1}{1 + \exp(-w^T x)}
$$

* Estimador de máxima verosimilitud

$$\min_w \left[ -\sum_i y_i \log(\sigma(w^T x_i)) + (1-y_i) \log(1 -\sigma(w^T x_i)) \right] $$
Demuéstralo.

* Resolución Numérica
???

La función de pérdida log-loss es un poco distinta a como la vimos antes
  * Tiene un menos delante, porque queremos minimizar y no maximizar la verosimilitud
  * Propiedad de la función sigmoidea `\(\sigma(-x) = 1 - \sigma(x)\)`

---

## Generalized linear models (GLM)

* Generalización de la regresión lineal con otras distribuciones de la familia exponencial

* Componentes:
  
  * Distribución de `\(y\)` con media `\(\mu\)`
  * Predictor lineal, `$$g(\mu) = w^T x$$` donde `\(g(\cdot)\)` es la función de media

* La función de media proporciona la relación entre la media de la distribución y el predictor lineal

* El inverso de la función de media, `\(g^{-1}(\cdot)\)` se conoce con el nombre de **función de enlace**

---

##Ejemplo: Regresión logística

¿Cuál es su distribución y función de enlace?

???

* La función de enlace es la inversa de la anterior,

`$$w^T x_i = g(\mu) = \ln\left(\frac{\mu}{1 - \mu}\right)$$`

---

## Ejemplo: distribución de Poisson

* Esta distribución está indicada cuando queremos modelizar conteos

* Función de media

`$$\mu = \exp(w^T x_i)$$`

* Función de enlace

`$$w^T x_i = \ln(\mu)$$`

* Otras distribuciones posibles son la Gamma, Exponencial, Multinomial, etc.

---

## GLMs en R

* La función para ajustar modelos lineales generalizados es `glm()`

* Tiene los mismos argumentos principales que `lm()`, pero además tenemos que especificar la distribución de la variables dependiente con el parámetro `family`

* Por defecto se usa la función de enlace "canónica", pero esto se puede modificar (ver ayuda)

* Implementa el algoritmo IRLS (Newton-Raphson), que se puede generalizar para cualquier GLM donde la distribución pertenece a la familia exponencial

Ejemplo: regresión logística


```r
library(MASS)
fit &lt;- glm(type ~ ., data=Pima.tr, family=binomial)
```

---

## Problemas (entre otros)

  * Poca flexibilidad (Sesgo grande), pues asumimos linealidad
  
  * Se puede solventar complicando el modelo (a mano) pero...
  
  * ... esto puede incrementar la varianza.
  
  * Trade-off

---

## Regularización

* Regresión *ridge* (*MSE* + regularización `\(l_2\)`): `$$\min_w\, ||y - \Xbf w||_2^2 + \lambda ||w||_2^2$$`


---

## Lasso: motivación

* Métodos de selección: 
   
   * ![:colorText green](modelos interpretables)
    
   * ![:colorText red](proceso discreto, las variables están incluidas o no)


* Regresión *ridge*: 

  * ![:colorText green](proceso continuo, todos los coeficientes se reducen)

  * ![:colorText red](rara vez son exactanente 0, modelos no interpretables)


* Lasso es una técnica intermedia:

  * ![:colorText green](reduce algunos coeficientes)
  
  * ![:colorText green](pone el resto a 0)

???

Modelos seleccion: variables entran o salen del modelo

---

## Lasso: formulación

* Problema optimización: `$$\min_w\, || y - \Xbf w ||_2^2\quad \text{s.t. }\; ||w||_1 \leq t$$`

* Equivalente: `$$\min_w\, || y - \Xbf w ||_2^2 + \lambda ||w||_1$$`

* `\(\lambda\)` o `\(t\)` son hiper-parámetros

  * `\(\uparrow \lambda\)` o `\(\downarrow t\)`, se reducen los coeficientes (más regularización)

  * `\(\downarrow \lambda\)` o `\(\uparrow t\)`, aumentan los coeficientes (menos regularización)
  
* `\(t\)` suficientemente pequeño (o `\(\lambda\)` suficientemente grande), algunos coeficientes = 0

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
